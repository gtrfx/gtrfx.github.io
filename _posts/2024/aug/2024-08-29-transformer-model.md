---
title: "transformer model..."
tags: [aiml]
layout: post
author: "Keith"
---

뭐랄까 세상에 한참 뒤쳐져 있다보니 이렇게 흔해져버린 용어를 마주하고 웃음만 나고 있다.

Transformer model이라는 게 있다고 한다. 이게 그냥 이 바닥에선, 아니 그냥 평상시 사용하는 용어가 되어버린 거다. 그냥 수많은 문제 해결 방법 중에 하나인거다.

그러니까 기계를 복잡한 문제 해결의 도구로 사용하게 되는 거다. 덧셈 뺄셈 같은 걸 하려고 계산기를 쓰는 게 아니라 이런 저런 요소들을 한꺼번에 고려했을 때 최적의 답을 찾는 과정에 컴퓨터를 활용하는 거다. 더 쉽게 생각하면 바둑같이 나름 복잡하고 어려운 게임도 척척 잘 풀어서 다 이겨낼 수 있는 컴퓨터가 못 할게 뭐가 있나. 쉽게 말해서 어떤 재료들을 조합해서 음식을 만들 때 각각의 구성 비율을 어떻게 해야 최상의 맛을 끌어낼 수 있을지 하는 수준의 문제는 컴퓨터가 아주 쉽게 해낼 수 있는 것 아닐까?

이런 문제를 푸는 것도 transformer model이 해내는 거다.

그러니까, 쉽게 말해 내가 가져다 요리할 재료들을 입력이라고 하면 그것을 다른 형태의 값 (=수치, value, 그러니까 현재의 재료 조건)로 변환하는 것을 인코더라고 하고 여기에 내가 원하는 최종 결과 (=음식의 맛))를 표현하는 다양한 파라미터를 넣어주면 디코더가 그 재료들을 얼마나 넣어주어야 할지 결정해주는 거다. 다양한 파라미터라는 것은 신맛, 단맛, 짠맛, 매운 맛 등을 얼마로 해야할지에 해당할 거다.

그러니까 인코더와 디코더, 그렇게 크게 두 부분으로 구성되고 입력값의 일부가 인코더에 의해서 다른 형태의 값으로 변형되고 이 값과 함께 다른 입력 요소들이 더해져서 디코더를 통해 원하는 결과로 만들어지는, 그런 구조의 문제 풀이 모델인 거다. 

물론 여기에 LLM이 결합되면 인간의 언어를 통해서 문제를 입력하고 또 그렇게 얻어진 해답을 다시 인간의 언어로 되돌려 받을 수 있는 거다. 요약도 할 수 있고 대충 질문할 수도, 세분화해서 질문할 수도, 결과를 다른 식으로 보여줄 수도 있고, 이런 유사한 경우의 수많은 데이터와 비교했을 때 이 문제는 어느 유형에 들어가는지도, 이런 문제는 어떤 동기/논리로 나오게 되었는지 그래서 어덯게 전개될 것인지도 알려주게 되는 거다. 너무 황당하다. 그렇게 문제풀이 박스들을 계속해서 조합해버리면 이 추상적인 처리과정, 그러나 구체화가 어렵지 않은, 을 통해 컴퓨터가 내가 하려는 일의 기승전결도 다 알고 있고 (이미 이전에 해놓은 것들의 학습을 통해) 발생할 문제와 해결방법도 다 알게 되는 것이다. 

이를테면 내가 어떤 음식을 만들어 먹고 싶다고 이야기하면 어떤 재료를 어떤 비율로 넣어서 어떻게 조리하면 된다라는 것을 알려주는 것을 떠나 내가 왜 이 음식을 만들어 먹으려고 하는지, 그 이후 나의 신체 변화는 어떻게 될 것이며 등등을 아주 구체적으로 알 수 있게 되는 것이다. 단, 나에 대한 모든 데이터를 가지고 학습이 끝났다는 전제하에. 

이미 여기에 해당하는 것이 LLaMa와 같은 LLM을 들여다 쓰고 ChipNeMo라는 chip design을 위해 개발되었다는 model을 결합한 모델? 이라고 보면 될 것 같다. 그러니까, 내가 원하는 칩의 형상을 LLM과 chat을 통해서 확립하고 나면 그것을 최종적으로 칩의 설계자료로 만들어주는 것이다. 물론 자체적으로 모든 검증이 이루어져서 더 볼 게 없는 지경이 되는 거다. 물론 이 모델은 기존에 매우 잘 된 설계를 통해 학습했어야만 한다. 좋지 않은 모델로 학습했더라도 스스로 좋지 않은 부분을 자체적으로 최적화해가며 새롭게 나타난 패턴만을 학습했어야 되겠지만.

이렇게 되면 결과는 뻔한 것 아닐까? 업계의 상위는 뭐랄까 추상적인 아이디어를 가져다 준 쪽이 되고 하위는 학습에서 발생하는 수많은 현실적인 문제를 다듬어나가는 역할을 담당하는 것이 되고. 그래서 얻어진 결과물은 응용분야에 따라서 구독형태의 서비스 비용을 받아가며 계속해서 수많은 데이터를 취득하며 유지 보수가 되는. 그러니까 설계와 검증에서 소모되던 인력들은 모두 역할을 잃게 되는 그런 결과를 초래하게 되지 싶다. 오직 새로운 데이터를 만들어낼 수 있는 위치의 사람들만 남게 되는. 다시 말해 AI/ML도 하지 못하는 fine-tuning/supervising을 하는 레벨만 남게 되는 거다. 쉽게 말해 중간 결과로 나온 것이 똥인지 된장인지, 똥과 된장의 비율이 어느 정도가 되어야 최적의 결과인지 감별해서 컨트롤 할 수 있는 입지의 사람들만.