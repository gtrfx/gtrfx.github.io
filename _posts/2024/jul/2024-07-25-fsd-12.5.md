---
title: "FSD 12.5..."
tags: [EV, tesla, FSD]
layout: post
author: "Keith"
---

FSD 12.4.3이 배포될 때만 해도 외부 테스터들이 받아서 시험한 다음 날 나한테도 배포가 되었기에 제법 기뻤는데, 이번엔 그렇지 않았다. 실제로 오늘 배포된 것들을 보니 배포량이 지난 번의 절반도 안되었던 걸 보면. 그 이유는 이렇다.

FSD가 12.5에 들어서는 대놓고 HW4, Model Y 위주로 개발하겠다고 하더니 어제는 Model Y, HW4위주로 배포 되었고 오늘은 Model S/3/X/Y HW4 차량으로 배포되었다. HW3은 어떻게 되는 거냐고 누가 일론 머스크에게 물어보니 뻔한 답이 왔다. HW3는 코드 최적화를 해야 된다고.

대개 이 답변에 대해 긍정적으로 반응하는 사람은 없는 것 같다. 그의 말을 빌자면 parameter의 개수가 5x가 되었으니까 어떤 NN를 쓴다고 하든 계산량이 필히 아무리 못해도 5배 이상은 늘었을테니 시스템부하의 여유가 있는 HW4에서 개발했고 HW3으로 오려면 최적화를 해야한다는데, 어차피 컴파일러가 최적화를 했음에도 이 지경이란 말이니까 어느 정도 타협해야 원하는 결과를 얻게 되지 싶은데, 그 타협이란 게 적절한 수준에서 HW4에서 하던 것들의 일부를 떼어버린다는 말이 되겠다. 그러니까 코드 최적화라는 것은 HW4에서 적당히 버릴 거 버려가면서 한 결과를 가져다가 HW3에 쓴다는 말이 되어야지 HW4 따로 HW3 따로 하면 그건 말이 안된다.

어쨌든 이렇게 HW3의 시대도 저물게 되는구나 한다.

Code를 까보지 않으니 알 수 없지만, 이미 FSD가 11에서 12로 넘어가면서 300k 라인의 conditional statement를 deep learning으로 대체했다는 이야기가 있었다. 복잡한 문제를 풀려면 수많은 if then을 쓰거나 아니면 미리 결정해놓은 lookup table을 쓰는 방법이 있는데, 사실상 neural network의 경우는 lookup table에 가깝다고 봐야할 것 같다. (물론 여기서 반기를 드는 사람들이 있겠지만) Deep learning의 좋은 점은 이미 알고 있는 상황을 교육시켜서 lookup table처럼 활용할 수 있고 lookup table에서 참조할 수 있는 상황이 아닌 상황이라든가 뭔가 좀 fuzzy한 상황에 대해서도 그럴싸한 대답을 내주는 것이라고 생각한다. 이를테면 상황 1도 아니고 2도 아닌 1.5 정도 되는 상황이 발생하면 상황 1과 2의 중간 정도에 해당하는 결과값을 주는 거다. 단순 lookup table로 한다고 하면 interpolation을 한 경우라고 할 수 있는데, lookup table도 차원을 한없이 늘려가는 것이 쉽지 않지만 deep learning에서는 입력의 개수를 늘리고 node수를 적당히 늘려주면 되니까. 물론 문제를 풀기 위해 필요한 최소의 연산량/메모리에 비하면 엄청나게 많은 양의 자원을 소모해야 하는 단점이 있는데, if then을 수도 없이 사용해야 하는 경우에는 이런 묻지마 방법이 효과가 있다고 생각한다.

