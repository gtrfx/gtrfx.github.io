---
title: "ollama를 돌려봤다.."
tags: [llm]
layout: post
author: "Keith"
---

ollama에 llama3를 돌려봤다가 맞다.

2700x와 7950x에서 돌려봤는데 (GPU는 둘 다 다 AMD GPU 5900이다) 속도의 유의미한 차이는 못 느꼈다. GPU가 있으나 마나한 5950x에서 돌려봤을 때도 별 다른 차이가 느껴지지 않았다. 다만 ChatGPT 더러 느리다 느리다 해도 엄청나게 빠른 것이었구나 할 뿐. 또 chatGPT 정도면 엄청나게 방대한 데이터가 있어야 할 것 같은데, 생각보다 weight 파일이 크지 않다는 점 (물론 이게 엄청나게 양자화된 것이란 것은 안다), llama3 8B 버전은 고작해야 4.7GB 정도니까 말 다했지 싶다.

GPU의 로드는 확인 못해봤는데, CPU는 모든 코어를 풀파워로 굴릴 때의 로드로 올라가고 있는 걸로 봐서, 또 그게 답변의 한글자 한글자를 찍어내고 있을 때 사정없이 돌고 있는 걸로 봐선, 모두 다 엄청난 곱셈/덧셈을 통한 결과물이라는 것을 알 수 있었다. MLP가 몇 개의 layer로 되어있는지 확인해보진 않았지만 2개의 layer로 XOR 문제를 풀 수 있게 되었다며 엄청난 희망을 가졌던 이들이 그 이후로 어려운 문제를 풀지 못해 (아니 풀더라도 그걸 설명하는 방법을 찾지 못해) 죄다 호부호형하지 못하는 암울한 시절을 살았으니. 이게 이렇게 현실화 되는 것을 나도 생전에 집에서 굴러다니는 컴퓨터를 통해서 볼 수 있게 되었다는 게 놀랍다. 

웨이트는 이렇게 작은데 할 수 있는 것은 사실 엄청나게나 많고 스스로 이해하고 판단하고 할 수 있다는 게 놀랍다. 아니 놀랍지 않아야 한다. 애초에 신경망이 나왔을 때 그러라고 만든 것이었고 layer를 많이 쌓으면 분명히 어려운 문제도 잘 풀 수 있겠거니 했지만 weight를 구할 방법을 못 찾아서 힘들었던 것이니까. 그게 7-80년대 얘기니까 40년이 넘게 지나서 이렇게 된 거다. 

낙수물이 끝없이 떨어지다보면 바위를 뚫는다 했던가? 그 시절 신경망을 전공한다고 하면 뭐랄까 답도 안나오고 스스로 분석도 못하는 걸로 사기친다고 했는데, 막상 해를 구하는 방법도 알아내고 했지만 이 거대한 신경망이 어떤 방법으로 놀라운 수준의 지능을 갖는지 모른다고 하니까 그 방면으로 여태 답이 없는 것은 마찬가지겠지만 역시나 이렇게 하다보면 언젠가는 알게 되겠지 하는 거다.

일단 코드를 짜는 것을 도와주는 과정에서 사용하다가 더 나아가서는 글을 쓰고 말을 하는 것 까지 전부 다 도와주게 되면 사람은 되려 복대를 찬 사람의 허리가 점점 약해지듯이 인공지능에 너무 의지하다가 멍청이가 되어버리는 것은 아닐까 하는 생각이 든다. 어려서부터 엄마가 이거 저거 다 해주다보면 애가 멍청해지는 것과 같다고나 할까.

어쨌든 연산능력이 확연하게 차이가 나는 시스템 3개를 돌려서 비교했을 때 유의미한 차이를 못 느꼈으니 이것을 폰에 넣어서 하겠다느니 하는 거다. 과연? 아마도 지금보다 훨씬 선폭이 가는 반도체를 만들어야 발열과 전력소모 둘 다 잡을텐데 간단한 채팅 한 번에 폰이 녹아내릴 정도의 열이 생기지 싶은데 지금의 기술로는. 물론 MLP를 양자화하는 능력을 더 키워서 또 데이터를 실어나르는 능력을 더 키워서 (내가 보기에 진작에 이 부분은 기술 포화가 되었을 것 같은데)하면 더 빨리 더 덜 열나게 어려운 문제를 풀 수 있겠지 싶다만.

문제의 해결 방법이 예전 같으면 완벽한 해를 얻어서 해결해내는 방향으로 같다고 하면 지금은 Ai, 다시말해 거대한 MLP와 weight로 이루어지는 기계가 시행착오를 통해 학습해낸 뒤에 풀어내는 방법으로 가게 되면 인간이 골머리를 썩을 이유는 없지 싶다. 한번 문제를 풀면 두 번 세번 응용 문제도 쉽게 풀어낼 뿐더러 복잡한 수식으로부터는 그냥 해방이 되는 거다. 물론 그 해는 통계적으로 완벽에 가까울 뿐이지 완전해를 냈을 때처럼 100% 딱 들어맞는다고는 할 수 없겠지만.

뭐랄까 MLP를 잘 만들면 패턴인식이나 잘하면 다행이겠다 했던 시절이 지나고 나니 이런 거대언어모델이라는 게 나와서 사람의 언어를 사람을 능가할 정도로 잘 구사하고 거기에 방대한 데이터를 가지고 학습시켜주면 엄청난 문제해결 능력까지 갖게 된 것은 정말로 놀랍다. 이젠 그게 응응 프로그램의 하나로 고작 몇 GB 수준의 메모리를 차지하고 돌게 되었다니.

내가 이제 이 세대의 기차 칸에서 마지막 몇 칸을 남겨두고 있구나 하는 생각도 든다고 해야할까? 그런데 생각보다 사람들은 이 엄청난 것에 대해 별달리 놀라워한다거나 두려워하는 느낌이 없는 것 같다. 이미 수 많은 과학자들이 우려 섞인 의견도 내고 너무 심하게 개발하지 말자는 법안도 내놓고 하니까 그런 것일까. 

몇 개의 인공지능 모델에 내가 평소에 답답해 하는 문제에 대해 질문했더니 역시나 하나같이 중립적인 의견을 내놨다. 다 좋은데 AI는 그걸 교육시킬 때 이렇게 중립적인 것들만 가져다가 시켜놔서 하나같이 다들 개성이 없구나 했다. 보잘 것 없는 촌동네의 아저씨이지만 신문물을 맞이하고 보니 뭔가 또 다른 것들을 해보고 싶은 의욕이 스물스물 솟아나온다. 

역시나 새로운 걸 경험해보고 생각해보고 하는 것은 이렇게나 재미있는 일이다. 그것을 직접 대면해서 느껴보기 전엔 '설마...되겠어?' 라든가 '그거 다 뻥일 거야..' 등등의 부정적인 생각을 하게 마련인데, 막상 내 눈앞에 벌어지는 광경을 믿어야 하는 상황에 이르러서야 깨닫음 같은 걸 얻는 듯 하다. 왜 이렇게 어리석을까 싶어도 이게 나란 인간의 한계인 것을 어찌할까? 

신기하게도 있지 않을 것이 곧 있게 될 것이란 것은 알아도 그것이 있게 되어야만 그것으로 뭔가를 할 수 있다는 것을 알게 된다니 얼마나 한심한가? 상상력이란 게 나에겐 허무맹랑한, 다시 말해 실현 불가능한 것을 떠올리는 힘 따위로 받아들여진지 오래인가보다. 인간의 머리로 떠올렸다는 것은 이미 실현되었거나 그것이 조만간 실현될 것이란 것이라고 보면 그것이 실현되면 무엇을 해볼 수 있겠다, 무엇을 해야겠다 하는 것 역시 어려운 생각이 아닌 거다. 그런데 누군가 내 눈앞에 떡하니 가져다주기 전엔 계속해서 모르는 채로 있는거다. 그렇게 인공지능의 시대도 이제 일상으로 와버렸다. 이 정도 크기면 이제 폰에도 들어가고 차에도 들어가고 하는 건 시간 문제고.

시각으로, 음성으로 나에게 도움을 주는 또 다른 뇌가, 아니 아예 뇌파 혹은 그외의 특수화된 전기신호로 나의 진짜 두뇌와 통신하는 내 두뇌의 확장팩이 곧 되어버리겠지. 곧 모든 사람들이 엄청나게 정교하고 잘 다듬어진 언어로 이야기하고 모든 언어로 능숙하게 이야기할 수 있는 시절이 와버린 거다. 더 이상 외국어를 잘 하는 것이 별 다른 특기가 아닌 시절이 오는 거다. 

왜? 내가 한국어로 개떡같이 작성하는 내 블로그 몇 개를 가져다가 4.7GB짜리 모델에 넣어 요약을 시켜봤는데 그 결과가 내가 요약한 것보다도 더 칼날 같이 정확했기 때문이다. 되려 내가 이런 뜻으로 쓴 것이었나? 를 알게 되는 놀라움까지 주었으니까. 나는 그냥 나의 의식의 흐름에 따라 적어내려 간 것인데 요약을 하고보니 내가 가진 생각이 이러했구나를 알게 되는 그런 거다. 