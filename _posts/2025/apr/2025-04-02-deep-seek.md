---
title: "DeepSeek transformer model..."
tags: [life]
layout: post
author: "Keith"
published: false
---

AI에 전적으로 문외한이었다가 슬슬 관심을 갖게 되다보니 이제서야 deepseek에 대해서 들여다볼 수 있게 되었다.
많이 느린 감은 있지만 이것만으로도 장족의 발전이 아닌가 한다.

최근의 AI의 두 축은 transformer와 diffusion이라고 본다.

여기서 transformer에서는 attention이라는 개념이 뭔가 깨닫음의 경지로 올라와야 어느 정도 이해를 할 수 있다고 생각한다.

attention에 대해서 이야기 하자면, 아주 짧게 말해서 하나의 입력 (문장)을 Q/K/V 이 3가지 값으로 분석하고
그걸 이용해서 attention이라는 중간 값을 끌어내고 이것을 이용하여 인간의 언어를 패턴화하여 학습한다 로 이해한다.

DeepSeek은 이 일반화된 transformer의 계산량을 줄여서 여러 가지 성능을 한꺼번에 끌어올린 아이디어라고 봐야 될 것 같다.



