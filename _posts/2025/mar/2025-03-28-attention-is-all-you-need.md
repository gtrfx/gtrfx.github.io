---
title: "2017년 Attention is all you need를 실험해본다..."
tags: [LLM]
layout: post
author: "Keith"
published: false
---

AI에 관심 갖기 시작한지 이제 딱 5일 된 것 같다. 뭐 장족의 발전이 있었는지는 모르지만 나름 몰두했다고 생각한다. 물론 Ai가 그걸 이해하는 데 나름의 도움을 주었고.

그런데 공부하다 보니 LLM 관련 용어들이 너무 많은 데 그 개념이란 게 다른 세계에서 놀던 사람에게는 참으로 작의적으로 보여서 어쩔 수 없이 실험을 하기에 이르렀다.

이미 LLM과 관련된 실험은 한 두 번 해봤지만 속도가 너무 느리고 중간 결과를 뽑아서 본다는 게 어쩌다 간단한 프로그램을 돌리면서 중간에 breakpoint 걸어서 확인하는 것과는
비교가 안되게 불편해서 엄두가 나질 않았다.

그런데 아무 것도 하지 않으면 내내 그냥 내 머릿속에서는 정의가 확실하지 않은 애매한 개념으로 남을 것 같기에 주말을 그냥 투자하기로 했다. 

GPU가 없으니 어쩔 수 없이 CPU로 돌릴 수 밖에 없을 것 같고.

일단 파악이 가능한 용어들만 적어보기로 한다.

### embedding

그냥 단어를 숫자에 매핑하는 tokenizing을 얘기하는 것으로 이해된다.

### attention

이게 가장 중요한 개념인 듯 한데, 그 개념이 작의적이다. 잘은 모르겠으나 이런 값을 뽑아낸다는 것 자체가 실험을 거듭하다가 나온 어떤 의미 있는 결과를 내주는 모양인데,
나름 어떤 의미를 부여하여 명명해버린 것 같다. 

그냥 입력 텐서에 linear matrix를 곱해서 나온 값 3가지를 Q/K/V라 하고 이들의 관계를 나름 정의해놓고 그 결과값을 attention으로 명명한다.

그냥 한가지 attention만 뽑아내면 잘 안될 것 같으니 이걸 병렬로 확장해놓은 것을 multi-head attention이라고 한다.

어쨌든 이렇게 해서 나온 결과를 encoder와 decoder가 활용한다. 

### Positional encoding

RNN처럼 문장을 순차적으로 입력해서 처리하지 않으려 하고 보니 문장에서 단어의 순서를 숫자화해서 망에 넣어주어야 하니 임의로 어떤 function을 정해서 넣어준다.

이 논문에서는 sin/cosine 함수를 사용하고 있다. 단어의 위치가 달라지면 그 단어를 tokenzing한 결과에 곱해져서 값을 비트는 효과를 갖는다. 같은 단어라도 위치에 따라 다른 값이 되게 만드는 일종의 실험적 장치인 듯 하다.


논문에서는 P100 GPU 8개를 가지고 실험했다고 한다. position을 알려주기 위해 이런 작의적인 함수를 도입하고 있는 것을 보면 뭐랄까 이 개념은 상업용 서비스로 발전하기 전까진 계속 이 모양이었거나 아무 생각없으면 계속 그대로 사용했거나 하는 거다.

transformer를 RNN과 구분해서 그 성능의 장점을 이야기할 때 문장을 순서대로 입력하지 않고 한꺼번에 입력하고, 그 때 이 위치 정보를 입력해주는 것이라고 하는데, 글쎄 이 또한 어떻게 받아들여야 할지 잘 모를 일이다.


### self attention을 쓰는 이유

이미 알려진 내용: RNN을 쓰면 gradient가 사라지는 문제가 발생
Self attention: 병렬화가 가능함. RNN처럼 피드백을 하지 않음. 계산량이 많지 않다 (뭐에 비해?)
장거리 의존성?


