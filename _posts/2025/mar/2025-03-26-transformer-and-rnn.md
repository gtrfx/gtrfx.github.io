---
title: "왜 트랜스포머 트랜스포머 하나 했더니만..."
tags: [llm]
layout: post
author: "Keith"
---

나의 잛은 지식으로 트랜스포머라는 것이 인코더와 디코더로 구성되는 NN layer의 그룹 이런 것으로 알고 있었는데, 그 말이 틀렸다고는 할 수 없지만, 그 자체로는 별 달리 의미가 없는 것이 이것이 왜 좋은지 왜 쓰여지고 있는지가 설명이 안되어서 꽤나 답답했는데, 어렴풋이나마 이해가 되고 있다.

---------

멀리 갈 것도 없이 2017년에 나온 attention is all you need라는 논문에 나온 모델의 구조를 사람들이 **transformer**라고 부르는 것으로 이해가 된다. 이 구조의 장점은 일반적으로 RNN처럼 recurrent한 구조의 NN을 쓰면 feedback을 하는 시스템의 문제 - 원하지 않게 어떤 값이 너무 작아져서 사라지거나 (그 때문에 매우 높은 precision을 써야 한다거나) 아니면 발산해버리거나 하는 - 를 극복하는 아이디어이기도 하고, feedback을 하는 system은 병렬화를 할 수 없는데, 이 구조로 하면 병렬화를 할 수 있는 덕택에 크기를 맘대로 키울 수 있다는 장점까지 가지고 있는 거다.

--------

여기까지만 이야기가 나와도 RNN은 더 이상 쳐다볼 필요도 없는 옛날 구조가 되어버리는 느낌을 받는데, transformer라는 것이 나름 복잡한 구조를 가지고 있기 때문에 RNN으로 쉽게 구현해서 풀 수 있는 문제도 있기 때문에 무조건 transformer가 좋다고는 할 수 없겠지.

--------

왜? RNN은 sequence를 있는 그대로 취급하기 때문에 그리고 feedback을 하기 때문에 처리의 전후관계가 중요해. 따라서 순차적인 처리를 할 수 밖에 없다.
그러나 transformer (여기에서 나오는 개념)은 sequence를 한꺼번에 입력하고 그 때 각각의 token의 위치에 대한 정보도 같이 전달해. 전후 관계가 입력의 순서에 따라 정해지는 것이 아니라
입력과 순서에 대한 정보를 한 꺼번에 넣어주는 거야. 그러니까 전후관계 역시 한꺼번에 처리 되기 때문에 순차적으로 처리할 이유가 없어. 다시 말해 앞의 결과가 있어야 지금의 처리를 할 수 있는 게 아니야.
그러니까 앞에 과정이 끝날 때까지 기다릴 필요가 없어. 

---------------

뭐랄까 이 세계에서 사용하는 용어는 다른 (전기/전자) 분야의 용어들과 같은 것들을 꽤나 사용하지만 그 개념이나 정의가 뭐랄까 더 추상적이고 작의적으로 들려서 적응에 좀 시간이 필요한 것 같다.

일단 transformer만 쳐다봐도 transformer는 encoder와 decoder로 구성된다고 한다. 왜 이래야만 하는지 알 수 없지만, encoder가 입력의 형태를 어떤 다른 형태로 변환한다고 생각하면 그렇구나 할 수 있지만, decoder는 왜 또 붙는 건가? 두번 변환한다는 건가? 일반적으로 encoder와 decoder를 붙여놓으면 다른 형태로 변환되었다가 원래 모양으로 되돌리는 걸로만 생각할 수 밖에 없는데, 여기선 또 그렇지 않다.

----

대충 이해해 보면 이 구조가 번역기를 만들다가 창안해낸 구조다 보니 그렇게 되는 거라고 판단이 된다. 그러니까, 번역기를 만들던 사람들의 생각으로는 어떤 언어로 된 입력을 받고 나면 그것을 특정 NN layer를 통과시키고 나면 그것은 그 문장의 의미를 가지고 있는 다른 형태의 (그러니까 (언어) 중립적인 형태의) 정보가 되고 그 어떤 중립적인 정보를 다른 언어로 변환하는 또 다른 NN모듈을 통과시키면 다른 언어로 변형이 되야하니까 그렇게 부른 것 같다. 다시 말해 언어 중립적인 정보 (의미?)를 가지고 있는 것으로 바꿔주는 것을 인코더, 그리고 그 정보를 받아서 다른 언어의 형태로 내보내는 것을 디코더라고 부른 것이지 하는 것이다.

---
2017년에 나오는 유명한 논문에 나왔던 모델의 구조가 이 아래 그림과 같다.

![transformer model architecture](https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png)

그림에 보이는 이 구조가 어쩌다 나오게 된 것인지는 논문을 가지고 보면 알 수 없지만, 수 많은 실험 끝에 나온 결과물이라는 것은 알겠다. 여기서 가장 특별하게 보이는 것이
- positional encoding
- multi-head attention

이라는 것이고, 그게 encoder와 decoder 모두에서 큰 역할을 하고 있다는 것 까지 이해할 수 있다.

---

그럼 도무지 이 attention이란 게 무엇이냐. 이미 얘기한 바와 같이 attention이란 것이 주목해야 할 것만을 골라내어 (결과에 반영시키겠다) 뭔가를 처리하는데 도움을 주는 것처럼 보인다. 그러나, 솔직히 이게 구조적으로 왜 좋은 것인지 그 원리를 이야기하라면 난감한 측면이 있다. 원작자가 어떤 생각으로 만들었는지 나의 능력으로는 잘 이해가 가질 않으니까. 그런데 있는 사실만 좀 나열해보자면, 일단 내부적으로 하나의 입력에 대해서 3가지 중간 값을 뽑아낸다.

```
Query, Key, Vector
```

왜 그 내부 값들을 이렇게 부르는지는 잘 모르겠다만. 어쨌든 3개의 중간값들이 있다. 물론 입력을 linear layer에 퉁과시킨 결과값들이다. 

아래 그림은 scaled dot attention과 이걸 병렬로 확장시킨 multi-head attention이라고 불리우는 것이다. 원문에 있는 걸 그대로 가져왔다.

![attention](https://media.geeksforgeeks.org/wp-content/uploads/20240110170625/Scaled-Dot-Product-and-Multi-Head-Attentions.webp)

