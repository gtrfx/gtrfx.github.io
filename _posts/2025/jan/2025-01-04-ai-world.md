---
title: "요즘 사람들이 이야기하는 AI..."
tags: [life]
layout: post
author: "Keith"
---

내가 대략적으로 관찰한 바, AI에 대해서 이야기하는 사람들은 다음과 같은 부류로 나눠졌다.

- AI 관련 주식에 관심을 갖는 사람들
- chatgpt, lama 혹은 apple intelligence를 실생활에 어떻게 잘 사용할까 관심 갖는 이들
- 유튜브 돈벌이를 위한 AI 활용하는 방법에 관심 갖는 사람들
- pytorch 같은 개발툴에 관심 갖는 이들

실제로 AI관련으로 사업을 하겠다거나 하는 사람들은 못 봤고 (내가 만나는 사람의 폭이 매우 좁아서) 90% 이상의 사람들은 별로 관심이 없었고 그렇다고 모른다는 티는 내기 싫으니 어디서 주워들을 이야기를 읊는 수준이다. Github copilot 같은 것을 일할 때 쓴다는 사람도 있긴 했지만, 그다지 큰 도움을 받는 것처럼 이야기하진 않았다.

내가 AI를 활용하는 방법은 어떠하냐고?

- 글을 써야 할 때 내용을 늘리거나 해야 할 때
- 공부를 해야 되는데 내용을 요약해야 할 때
- 누군가를 위한 설명 자료를 제작해야 할 때

신기한 것은 생각을 말과 그림으로 표현할 때 AI의 효용성이 대단히 높다는 것이다. 또 남의 생각을 이해해야 할 때도 효과가 좋았다.

그 말인 즉, 사람들마다 저마다의 표현 방법이 있는데, 이게 표준화(?) 되지 못하고 군더더기가 많거나 너무 축약이 되있다거나 해서 제대로 이해하는 데 도움이 필요하단 말이다. 여기서 AI가 도움을 주는 이유는 나름 어떤 내용을 적확하게 표현한 자료로 잘 공부를 했기 때문이지 싶다. 최근 어떤 AI 서비스를 이용해서 내용을 바꿔 써 보라든가 요약을 하라고 하면 내 의도와는 다르게 적어내거나 결과물이 원본보다 나쁜 경우를 종종 마주하게 되는데, 아마도 이것은 저작권 때문에 허접한 자료를 가지고 공부를 했기 때문이지 싶다.

AI가 세상에 도움을 주는 것도 맞고 (여기서 AI는 주로 LLM을 말한다) AI를 제대로 구현하기 위해서 좋은 하드웨어가 필요한 것은 알겠는데 무조건 방대한 지식을 가지고 있다고 해서 다 좋은 것도 아니고 딱 나에게 적당한 수준의 양질의 정보를 주는 것이 중요하다고 생각한다. 그러니까 쓸데없이 파라미터가 많기 보단 딱 적당한 수준으로 적당히 빠른 AI 서비스가 필요한 거다. 무엇보다 군더더기나 이상한 내용들이 포함되지 않으려면, 또 법적인 문제에 휘말리지 않으려면 딱 정해진 영역의 지식만 습득해야 한다고 본다. 

최근의 LLM의 토대가 되었다는 'Attention is all you need' 라는 논문을 보고 있다. 워낙 유명한 논문이긴 하지만 관련 분야 배경지식이 충분히 있어야 이해가 가능하다. 사실상 나와야 할 아이디어는 이미 2010년대에 다 나왔고 그것을 실전에서 어떻게 잘 응용하느냐의 문제만 남은 것인데 이게 이렇게 큰 히트를 치게 된 것은 대략 7-8년 이후이니까, 나름 첨단 분야를 한다, 그것도 제법 많은 사람들이 뛰어들어서 좀 늦은 것 아닐까 싶은 때라도 못해도 7-8년은 지나봐야 똥인지 된장인지 구분이 가능하겠구나 하게 되는 거다. 사실 이 논문을 보지 않아도 LLM을 개발 사용하는 것은 매우 쉽다. 그만큼 관련 커뮤니티가 제법 컸기 때문인데 뭐 이를테면 내가 건반으로 음악을 작곡하려는데, 건반만 구입하면 되고 필요한 음색을 꺼내쓰면 (그러나 약간의 튜닝만 해주는 정도만 요구) 되는데, 건반과 음원이 어떻게 만들어지는지 원리나 응용예를 전부 알 필요가 없는 상황이 되어버렸달까. 

논문 내용을 보면 보여지는 예에서 P100이라는 꽤 오래된 GPU 8개를 가지고 12시간 정도 들여서 어떤 문제에 대한 학습을 시켰다는 이야기가 나오는데, 이게 적당한 비교인지는 몰라도 요새들 비싼 GPU로 이야기하는 H100과 비교하면 대략 32bit float를 기준으로 1/5 정도의 성능 밖엔 안된다고 봐야지 싶은데, 장비의 희소성 때문에 가격은 엄청나게 비싹도 하거니와 메모리가 꽤나 크기 때문에 과거 8개로 작업했다면 지금은 못해도 1개의 GPU가 충분히 커버가 가능하지 싶다.

왜 이런 말을 하냐면, 개인이라 소규모 그룹이 필요로 하는 지식을 가지고 LLM을 training을 하고 그것을 개개인이 자체적인 inference engine을 돌려서 사용하는 응용예를 가정하면 - 나는 이게 좀 실현 가능성이 높다고 생각한다 - 지금의 H100으로 구성할 수 있는 서버를 하나 두고 (혹은 임대하고) LLM을 개발/유지보수 하면 어느 수준 이상의 목표는 충분히 이룰 수 있지 않을까 하는 거다.

사실 특정 목적을 위해서 제작한 LLM이 혹은 MLM/SLM이 쓸데없이 복잡할 이유는 없는 것 아닌가? 게다가 자료가 충분히 양질의 것이라면 더더욱 말이다. 

결국, 이러한 그룹에서 필요한 서비스는 목적에 맞는 LLM의 개발/유지/보수 및 배포니까 개발인력을 해당 조직 단위에서 채용해야 할 이유도 없고, 하나의 개발 회사가 이런 일들만 대행해주면 되지 싶다. 다만 저작권과 같은 법률적인 문제를 해결해 줄 수 있는 서비스도 역시나 필요하게 될 것이라 보지만 역시나 늘상 필요한 것은 아니니 필요할 때마다 위탁을 하는 식으로 가면 될 것 같고.

그러니까 개발 회사에서 하는 일의 수준이란 것도 고객이 제공한 자료들을 잘 refine해서 (어차피 자동화로 해야 되고 이를 위한 룰을 정하는 것이 노우하우가 될 듯 하다) 그것을 이상한 군더더기 없이 학습을 시키고 검증을 위한 자동화 작업을 수행시키는 것이라고 본다. 어디까지나 학습/검증을 위한 자동화를 위한 룰셋이 얼마나 잘 갖춰졌냐가 결과물의 품질을 결정하게 될텐데, 이 역시도 AI를 이용해야 할 것이라고 본다. 

이미 사람들의 응용 영역이 단순히 text(image)-to-text generation을 넘어서 text(image)-to-image, text(audio)-to-audio, text(image)-to-video로 넘어가 버린지 오래라 미래의 AI 모델이란 게 어떤 형태로 통합될지 자못 궁금하기도 하다. 